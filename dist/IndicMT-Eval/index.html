<!DOCTYPE html><html lang="en" data-theme="mytheme"> <head><meta charset="UTF-8"><meta name="description" content="AI4Bharat Datasets"><meta name="viewport" content="width=device-width"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v4.14.5"><!-- Add this to your HTML file --><!-- <link
s      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/choices.js/public/assets/styles/choices.min.css"
    /> --><script type="module" src="https://cdn.jsdelivr.net/npm/choices.js/public/assets/scripts/choices.min.js"></script><title>IndicMT-Eval</title><link rel="stylesheet" href="/astro/explore.D-UsDqG8.css"></head> <body class="container mx-auto px-4 mb-4 md:mb-8">  <div class="navbar bg-base-100"> <div class="flex-1"> <a href="/IndicMT-Eval" class="text-3xl font-bold bg-gradient-to-r from-orange-600 via-red-500 to-black inline-block text-transparent bg-clip-text">IndicMT-Eval</a> </div> <div class="flex-none"> <ul class="menu menu-horizontal px-1"> <li><a href="/IndicMT-Eval">Home</a></li> <li>  <a href="https://docs.google.com/spreadsheets/d/1HEwlBTLvN2NOXLxiBpIt_GVdHkjyvIo8DvQrncgto74/edit?gid=1528534260#gid=1528534260">Explore</a> </li> </ul> </div> </div> <h2 class="flex justify-center text-lg md:text-2xl text-secondary font-semibold md:font-normal"> A Dataset to Meta-Evaluate Machine Translation Metrics for Indian Languages </h2> <div class="divider"> <span class="text-sm font-semibold">Description</span> </div> <p class="text my-4 font-normal"> We contribute a Multidimensional Quality Metric (MQM) dataset for Indian languages created by taking outputs generated by 7 popular MT systems and asking human annotators to judge the quality of the translations using the MQM style guidelines. Using this rich set of annotated data, we show the performance of 16 metrics of various types on evaluating en-xx translations for 5 Indian languages. We provide an updated metric called Indic-COMET which not only shows stronger correlations with human judgement on Indian languages, but is also more robust to perturbations. </p> <ul class="menu menu-horizontal bg-base-200 rounded-box flex flex-row justify-center"> <li> <a class="link link-info" href="https://docs.google.com/spreadsheets/d/1HEwlBTLvN2NOXLxiBpIt_GVdHkjyvIo8DvQrncgto74/edit?gid=1528534260#gid=1528534260">
Explore Dataset
</a> </li> <li> <a class="link link-info" href="https://aclanthology.org/2023.acl-long.795.pdf" target="_blank">
Read Paper
</a> </li> </ul> <div class="divider" id="downloads"> <span class="text-sm font-semibold"> Downloads </span> </div> <article class="prose prose-headings:text-primary prose-a:text-secondary prose-li:marker:text-accent mx-auto"> 












<table><thead><tr><th>Resource name</th><th>link</th></tr></thead><tbody><tr><td>Dataset</td><td><a href="https://docs.google.com/spreadsheets/d/1HEwlBTLvN2NOXLxiBpIt_GVdHkjyvIo8DvQrncgto74/edit?gid=1528534260#gid=1528534260">IndicMT-Eval - Sheets</a></td></tr></tbody></table> </article> <div class="divider" id="details"> <span class="text-sm font-semibold"> Details </span> </div> <article class="prose prose-headings:text-primary prose-a:text-secondary prose-li:marker:text-accent max-w-none"> <h2 id="overview">Overview</h2>
<p>We contribute a Multidimensional Quality Metric (MQM) dataset for Indian languages created by taking outputs generated by 7 popular MT systems and asking human annotators to judge the quality of the translations using the MQM style guidelines. Using this rich set of annotated data, we show the performance of 16 metrics of various types on evaluating en-xx translations for 5 Indian languages. We provide an updated metric called Indic-COMET which not only shows stronger correlations with human judgement on Indian languages, but is also more robust to perturbations.</p>
<p>Please find more details of this work in our paper (link coming soon).</p>
<h2 id="mqm-dataset">MQM Dataset</h2>
<p>The MQM annotated dataset collected with the help of language experts for the 5 Indian lamguages (Hindi, Tamil, Marathi, Malayalam, Gujarati) can be downloaded from here (link coming soon).</p>
<p>An example of an MQM annotation containing the source, reference and the translated output with error spans as demarcated by the annotator looks like the following:
<img src="https://github.com/AI4Bharat/IndicMT-Eval/assets/23221743/0296986f-bb89-4044-88ef-b8fb71acf9ee" alt="MQM-example"></p>
<p>More details regarding the instructions provided and the procedures followed for annotations are present in the paper.</p>
<h2 id="setup">Setup</h2>
<h3 id="load-the-data">Load the data</h3>
<p>The easiest method to access / view the data is to visit this <a href="https://docs.google.com/spreadsheets/d/1HEwlBTLvN2NOXLxiBpIt_GVdHkjyvIo8DvQrncgto74/edit?usp=sharing">link</a>
More details in data folder</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>cd data</span></span>
<span class="line"><span></span></span></code></pre>
<br>
<h2 id="citation">Citation</h2>
<p>If you find IndicMTEval useful in your research or work, please consider citing our paper.</p>
<pre class="astro-code dracula" style="background-color:#282A36;color:#F8F8F2; overflow-x: auto; white-space: pre-wrap; word-wrap: break-word;" tabindex="0" data-language="plaintext"><code><span class="line"><span>@article{DBLP:journals/corr/abs-2212-10180,</span></span>
<span class="line"><span>  author       = {Ananya B. Sai and</span></span>
<span class="line"><span>                  Tanay Dixit and</span></span>
<span class="line"><span>                  Vignesh Nagarajan and</span></span>
<span class="line"><span>                  Anoop Kunchukuttan and</span></span>
<span class="line"><span>                  Pratyush Kumar and</span></span>
<span class="line"><span>                  Mitesh M. Khapra and</span></span>
<span class="line"><span>                  Raj Dabre},</span></span>
<span class="line"><span>  title        = {IndicMT Eval: {A} Dataset to Meta-Evaluate Machine Translation metrics</span></span>
<span class="line"><span>                  for Indian Languages},</span></span>
<span class="line"><span>  journal      = {CoRR},</span></span>
<span class="line"><span>  volume       = {abs/2212.10180},</span></span>
<span class="line"><span>  year         = {2022}</span></span>
<span class="line"><span>}</span></span>
<span class="line"><span></span></span>
<span class="line"><span>@article{singh2024good,</span></span>
<span class="line"><span>  title={How Good is Zero-Shot MT Evaluation for Low Resource Indian Languages?},</span></span>
<span class="line"><span>  author={Singh, Anushka and Sai, Ananya B and Dabre, Raj and Puduppully, Ratish and Kunchukuttan, Anoop and Khapra, Mitesh M},</span></span>
<span class="line"><span>  journal={arXiv preprint arXiv:2406.03893},</span></span>
<span class="line"><span>  year={2024}</span></span>
<span class="line"><span>}</span></span>
<span class="line"><span></span></span></code></pre> </article>  </body></html>